# **Reports - Model Outputs & Evaluation**

The `reports/` folder (located in the project root) stores **human-readable outputs** generated during experiments. These files are derived from MLflow-logged artifacts and provide a quick way to inspect model performance without navigating the UI.

## **General Structure**

```
reports/
├── keras_best_model_summary.txt     # Text summary of the best Keras model architecture
├── keras_classification_report.txt  # Precision, recall, F1-score for Keras model
├── keras_confusion_matrix.png       # Confusion matrix visual for Keras model
├── rf_classification_report.txt     # Classification metrics for Random Forest
├── rf_confusion_matrix.png          # Confusion matrix for Random Forest
├── rf_feature_importances.csv       # Feature importance scores from Random Forest
├── xgb_classification_report.txt    # Classification metrics for XGBoost
└── xgb_confusion_matrix.png         # Confusion matrix for XGBoost
```

## **Purpose**
- Provides **quick access** to evaluation outputs without opening MLflow UI.
- Useful for sharing results (e.g., attaching confusion matrices or reports in documents/presentations).
- Includes both **text summaries** (classification reports, model summaries) and **visuals** (confusion matrices).

## **Notes**
- Reports are automatically generated during experiment runs.
- Naming convention matches the model (`rf`, `xgb`, `keras`) for clarity.
- These files can be safely regenerated by re-running experiments.
